version: '3.8'

services:
  # Redis cache service
  redis:
    image: redis:7-alpine
    container_name: guardy-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - guardy-network

  # PostgreSQL database service
  postgres:
    image: postgres:16-alpine
    container_name: guardy-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ${DB_NAME:-floodguard}
      POSTGRES_USER: ${DB_USER:-floodguard_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-your_password}
      POSTGRES_INITDB_ARGS: "-E UTF8"
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/sensor_tables.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-floodguard_user} -d ${DB_NAME:-floodguard}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - guardy-network

  # Guardy AI API service
  api:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: guardy-api
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      # Application
      APP_NAME: "Guardy AI Microservice"
      APP_VERSION: "1.0.0"
      HOST: "0.0.0.0"
      PORT: "8000"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      DEBUG: ${DEBUG:-false}
      
      # Database
      DATABASE_URL: postgresql://${DB_USER:-floodguard_user}:${DB_PASSWORD:-your_password}@postgres:5432/${DB_NAME:-floodguard}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: ${DB_NAME:-floodguard}
      DB_USER: ${DB_USER:-floodguard_user}
      DB_PASSWORD: ${DB_PASSWORD:-your_password}
      
      # Redis
      REDIS_URL: redis://redis:6379
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_DB: 0
      REDIS_ENABLED: ${REDIS_ENABLED:-true}
      
      # Cache TTL (seconds)
      CACHE_TTL_FLOOD_RISK: ${CACHE_TTL_FLOOD_RISK:-300}
      CACHE_TTL_NOWCAST: ${CACHE_TTL_NOWCAST:-600}
      CACHE_TTL_ANOMALY: ${CACHE_TTL_ANOMALY:-60}
      CACHE_TTL_BATCH: ${CACHE_TTL_BATCH:-180}
      CACHE_TTL_EVACUATION: ${CACHE_TTL_EVACUATION:-900}
      
      # Performance
      MAX_BATCH_SIZE: ${MAX_BATCH_SIZE:-100}
      WORKER_THREADS: ${WORKER_THREADS:-4}
      PREDICTION_TIMEOUT: ${PREDICTION_TIMEOUT:-30}
      ENABLE_PROFILING: ${ENABLE_PROFILING:-false}
      
      # Models
      MODEL_PATH: /app/models
      ENABLE_MODEL_CACHING: ${ENABLE_MODEL_CACHING:-true}
      MODEL_WARMUP: ${MODEL_WARMUP:-true}
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
      - ./data:/app/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/models/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - guardy-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Nginx reverse proxy (optional - for production)
  nginx:
    image: nginx:alpine
    container_name: guardy-nginx
    restart: unless-stopped
    depends_on:
      - api
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    networks:
      - guardy-network
    profiles:
      - production

volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local
  nginx_logs:
    driver: local

networks:
  guardy-network:
    driver: bridge
